{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دادماتولز نسخش سال منتشر تولز بتونه کار متن براتون شیرین‌تر راحت‌تر کنه ایمیل ارتباط آدرس گیت‌هاب معرف حضور مبارک\n"
     ]
    }
   ],
   "source": [
    "from dadmatools.normalizer import Normalizer\n",
    "\n",
    "normalizer = Normalizer(\n",
    "    full_cleaning=False,\n",
    "    unify_chars=True,\n",
    "    refine_punc_spacing=True,\n",
    "    remove_extra_space=True,\n",
    "    remove_puncs=False,\n",
    "    remove_html=False,\n",
    "    remove_stop_word=False,\n",
    "    replace_email_with=\"<EMAIL>\",\n",
    "    replace_number_with=None,\n",
    "    replace_url_with=\"\",\n",
    "    replace_mobile_number_with=None,\n",
    "    replace_emoji_with=None,\n",
    "    replace_home_number_with=None\n",
    ")\n",
    "\n",
    "text = \"\"\"\n",
    "<p>\n",
    "دادماتولز اولین نسخش سال ۱۴۰۰ منتشر شده. \n",
    "امیدواریم که این تولز بتونه کار با متن رو براتون شیرین‌تر و راحت‌تر کنه\n",
    "لطفا با ایمیل dadmatools@dadmatech.ir با ما در ارتباط باشید\n",
    "آدرس گیت‌هاب هم که خب معرف حضور مبارک هست:\n",
    " https://github.com/Dadmatech/DadmaTools\n",
    "</p>\n",
    "\"\"\"\n",
    "normalized_text = normalizer.normalize(text)\n",
    "# <p> دادماتولز اولین نسخش سال 1400 منتشر شده. امیدواریم که این تولز بتونه کار با متن رو براتون شیرین‌تر و راحت‌تر کنه لطفا با ایمیل <EMAIL> با ما در ارتباط باشید آدرس گیت‌هاب هم که خب معرف حضور مبارک هست: </p>\n",
    "\n",
    "# full cleaning\n",
    "normalizer = Normalizer(full_cleaning=True)\n",
    "normalized_text = normalizer.normalize(text)\n",
    "print(normalized_text)\n",
    "# دادماتولز نسخش سال منتشر تولز بتونه کار متن براتون شیرین‌تر راحت‌تر کنه ایمیل ارتباط آدرس گیت‌هاب معرف حضور مبارک\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mutable default <class 'dadmatools.pipeline.adapter_transformers.adapter_config.InvertibleAdapterConfig'> for field invertible_adapter is not allowed: use default_factory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdadmatools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanguage\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# here lemmatizer and pos tagger will be loaded\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# as tokenizer is the default tool, it will be loaded as well even without calling\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# pips = 'tok,lem,pos,dep,chunk,cons,spellchecker,kasreh,itf,ner,sent'\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# nlp = language.Pipeline(pips)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/site-packages/dadmatools/pipeline/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TPipeline\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m supported_langs, langwithner, remove_with_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/site-packages/dadmatools/pipeline/language.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m master_config\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minformal2formal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Informal2Formal\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Multilingual_Embedding\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclassifiers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TokenizerClassifier, PosDepClassifier, NERClassifier, SentenceClassifier, \\\n\u001b[32m      9\u001b[39m     KasrehClassifier\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmwt_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MWTWrapper\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/site-packages/dadmatools/pipeline/models/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclassifiers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/site-packages/dadmatools/pipeline/models/classifiers.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdadmatools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcrf_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CRFLoss, viterbi_decode, CELoss\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/site-packages/dadmatools/pipeline/models/base_models.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madapter_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdapterType, XLMRobertaModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madapter_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdapterConfig\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/site-packages/dadmatools/pipeline/adapter_transformers/__init__.py:31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Configurations\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_albert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP, AlbertConfig\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALL_PRETRAINED_CONFIG_ARCHIVE_MAP, CONFIG_MAPPING, AutoConfig\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_bart\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BartConfig\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_bert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BERT_PRETRAINED_CONFIG_ARCHIVE_MAP, BertConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/site-packages/dadmatools/pipeline/adapter_transformers/configuration_auto.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_albert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP, AlbertConfig\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_bart\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BART_PRETRAINED_CONFIG_ARCHIVE_MAP, BartConfig\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_bert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BERT_PRETRAINED_CONFIG_ARCHIVE_MAP, BertConfig\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_camembert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CAMEMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP, CamembertConfig\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_ctrl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP, CTRLConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/site-packages/dadmatools/pipeline/adapter_transformers/configuration_bert.py:21\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\" BERT model configuration \"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01madapter_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelAdaptersConfig\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[32m     25\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/site-packages/dadmatools/pipeline/adapter_transformers/adapter_config.py:121\u001b[39m\n\u001b[32m    117\u001b[39m         config_dict.update((k, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    118\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m AdapterConfig.from_dict(config_dict)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;129;43m@dataclass\u001b[39;49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mPfeifferConfig\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mAdapterConfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m    124\u001b[39m \u001b[33;43;03m    The adapter architecture proposed by Pfeiffer et. al., 2020.\u001b[39;49;00m\n\u001b[32m    125\u001b[39m \u001b[33;43;03m    Described in https://arxiv.org/pdf/2005.00247.pdf.\u001b[39;49;00m\n\u001b[32m    126\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43moriginal_ln_before\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/dataclasses.py:1275\u001b[39m, in \u001b[36mdataclass\u001b[39m\u001b[34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[39m\n\u001b[32m   1272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap\n\u001b[32m   1274\u001b[39m \u001b[38;5;66;03m# We're called as @dataclass without parens.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/dataclasses.py:1265\u001b[39m, in \u001b[36mdataclass.<locals>.wrap\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m   1264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1265\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_process_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsafe_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1266\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mfrozen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1267\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mweakref_slot\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/dataclasses.py:994\u001b[39m, in \u001b[36m_process_class\u001b[39m\u001b[34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[39m\n\u001b[32m    991\u001b[39m         kw_only = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    992\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    993\u001b[39m         \u001b[38;5;66;03m# Otherwise it's a field of some type.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m994\u001b[39m         cls_fields.append(\u001b[43m_get_field\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_only\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m cls_fields:\n\u001b[32m    997\u001b[39m     fields[f.name] = f\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.12/dataclasses.py:852\u001b[39m, in \u001b[36m_get_field\u001b[39m\u001b[34m(cls, a_name, a_type, default_kw_only)\u001b[39m\n\u001b[32m    848\u001b[39m \u001b[38;5;66;03m# For real fields, disallow mutable defaults.  Use unhashable as a proxy\u001b[39;00m\n\u001b[32m    849\u001b[39m \u001b[38;5;66;03m# indicator for mutability.  Read the __hash__ attribute from the class,\u001b[39;00m\n\u001b[32m    850\u001b[39m \u001b[38;5;66;03m# not the instance.\u001b[39;00m\n\u001b[32m    851\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f._field_type \u001b[38;5;129;01mis\u001b[39;00m _FIELD \u001b[38;5;129;01mand\u001b[39;00m f.default.\u001b[34m__class__\u001b[39m.\u001b[34m__hash__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmutable default \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f.default)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for field \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    853\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not allowed: use default_factory\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[31mValueError\u001b[39m: mutable default <class 'dadmatools.pipeline.adapter_transformers.adapter_config.InvertibleAdapterConfig'> for field invertible_adapter is not allowed: use default_factory"
     ]
    }
   ],
   "source": [
    "import dadmatools.pipeline.language as language\n",
    "\n",
    "# here lemmatizer and pos tagger will be loaded\n",
    "# as tokenizer is the default tool, it will be loaded as well even without calling\n",
    "# pips = 'tok,lem,pos,dep,chunk,cons,spellchecker,kasreh,itf,ner,sent'\n",
    "# nlp = language.Pipeline(pips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dadmatools.datasets import SnappfoodSentiment\n",
    "\n",
    "\n",
    "\n",
    "snpfood_sa = SnappfoodSentiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: snappfoodSentiment\n",
      "version: 1.0.0\n",
      "task: Sentiment-Analysis\n",
      "splits: ['train', 'test', 'dev']\n",
      "description: source: https://huggingface.co/HooshvareLab/bert-fa-base-uncased-sentiment-snappfood\n",
      "size: {'train': 56516, 'dev': 6274, 'test': 6972}\n",
      "filenames: ['snappfood/train.csv', 'snappfood/test.csv', 'snappfood/dev.csv']\n"
     ]
    }
   ],
   "source": [
    "print(snpfood_sa.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Peyma': {'name': 'Peyma',\n",
       "  'version': '1.0.0',\n",
       "  'task': 'NER',\n",
       "  'splits': [],\n",
       "  'description': 'source: http://nsurl.org/2019-2/tasks/task-7-named-entity-recognition-ner-for-farsi/',\n",
       "  'size': 10016,\n",
       "  'filenames': ['peyma/600K', 'peyma/300K']},\n",
       " 'snappfoodSentiment': {'name': 'snappfoodSentiment',\n",
       "  'version': '1.0.0',\n",
       "  'task': 'Sentiment-Analysis',\n",
       "  'splits': ['train', 'test', 'dev'],\n",
       "  'description': 'source: https://huggingface.co/HooshvareLab/bert-fa-base-uncased-sentiment-snappfood',\n",
       "  'size': {'train': 56516, 'dev': 6274, 'test': 6972},\n",
       "  'filenames': ['snappfood/train.csv',\n",
       "   'snappfood/test.csv',\n",
       "   'snappfood/dev.csv']},\n",
       " 'PersianNer': {'name': 'PersianNer',\n",
       "  'version': '1.0.0',\n",
       "  'task': 'NER',\n",
       "  'splits': [],\n",
       "  'description': 'source: https://github.com/Text-Mining/Persian-NER',\n",
       "  'size': 976599,\n",
       "  'filenames': ['Persian-NER-part1.txt',\n",
       "   'Persian-NER-part2.txt',\n",
       "   'Persian-NER-part3.txt',\n",
       "   'Persian-NER-part4.txt',\n",
       "   'Persian-NER-part5.txt']},\n",
       " 'ARMAN': {'name': 'ARMAN',\n",
       "  'version': '1.0.0',\n",
       "  'task': 'NER',\n",
       "  'splits': ['train', 'test'],\n",
       "  'description': 'ARMAN dataset holds 7,682 sentences with 250,015 sentences tagged over six different classes.\\n\\nOrganization\\nLocation\\nFacility\\nEvent\\nProduct\\nPerson',\n",
       "  'filenames': ['train_fold1.txt',\n",
       "   'train_fold2.txt',\n",
       "   'train_fold3.txt',\n",
       "   'test_fold1.txt',\n",
       "   'test_fold2.txt',\n",
       "   'test_fold3.txt'],\n",
       "  'size': {'train': 15361, 'test': 7680}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dadmatools.datasets import get_all_datasets_info\n",
    "\n",
    "get_all_datasets_info().keys()\n",
    "#dict_keys(['Persian-NEWS', 'fa-wiki', 'faspell', 'PnSummary', 'TEP', 'PerUDT', 'FarsTail', 'Peyma', 'snappfoodSentiment', 'Persian-NER', 'Arman', 'PerSent'])\n",
    "\n",
    "#specify task\n",
    "get_all_datasets_info(tasks=['NER', 'Sentiment-Analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
